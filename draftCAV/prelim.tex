%!TEX root = draft.tex
\section{Preliminaries}

We formalize several abstraction relations between libraries using a simple
yet universal model of computation, namely labeled transition systems (LTS).
This model captures shared-memory programs with an arbitrary number of threads,
abstracting away the details of any particular programming system irrelevant to
our development.

A \emph{labeled transition system} (LTS) $A=(Q,\Sigma, s_0, \delta)$ over the 
possibly-infinite alphabet $\Sigma$ is a possibly-infinite set $Q$ of states with
initial state $s_0 \in Q$, and a transition relation $\delta \subseteq Q \times @S \times
Q$. The $i$th symbol of a sequence $@t \in @S^*$ is denoted $@t_i$, and the empty
sequence is denoted by $\epsilon$.
An \emph{execution} of $A$ is an alternating sequence of states and transition labels (called also actions)
$\rho = s_0, e_0,s_1\ldots e_{k-1},s_k$ for some $k>0$ such that $\delta(s_i, e_i, s_{i+1})$
for each $i$ such that $0\leq i<k$. We write $s_i\xrightarrow{e_i\ldots e_{j-1}} s_j$ \textcolor{red}{as shorthand for $s_i,e_i,...,s_{j-1},e_{j-1},s_j$ subsequence of $\rho$,} for any $0\leq i\leq j <k$
(in particular $s_i\xrightarrow{\epsilon}s_i$)\textcolor{red}{(I also propose to add subscript to the arrow mentioning the machine name like $s_i \xrightarrow{\alpha}_A s_j$ to avoid confusion between machines in the forward simulation definition. This will require us to change arrows in forward and backward simulation definitions.)}.
The projection $@t| \Gamma$ of a sequence $@t$ is the maximum subsequence of $@t$ over
 alphabet $\Gamma$. This notation is extended to sets of sequences as usual.
A \emph{trace} of $A$ is the projection $\rho | \Sigma$ of an execution $\rho$ of $A$. 
The set of executions, resp., traces, of an LTS $A$ is denoted by $E(A)$, resp., $Tr(A)$.
An LTS is \emph{deterministic} if for any state $s$ and any sequence $@t\in \Sigma^*$, there is at most
one state $s'$ such that $s\xrightarrow{@t}s'$.

\subsection{Libraries}

Programs interact with libraries by calling named library \emph{methods}, which
receive \emph{parameter values} and yield \emph{return values} upon completion.
We fix arbitrary sets $\<Methods>$ and $\<Vals>$ of method names and
parameter/return values. 

%\begin{example}
%  \label{ex:methods}
%
%  TODO
%
%  The method and value sets for the stack implementation in
%  Figure~\ref{fig:treiber} are $\<Methods> = \set{ \<push>, \<pop> }$ and
%  $\<Vals> = \<Nats> \u \set{ {\tt EMPTY} }$.
%
%\end{example}

\noindent
We fix an arbitrary set $\<Ops>$ of operation identifiers, and for given sets
$\<Methods>$ and $\<Vals>$ of methods and values, we fix the sets
\begin{align*}
  & C = \set{ inv(m,d,k) : m \in \<Methods>, d \in \<Vals>, k \in \<Ops> }
  \text{, and } \\
  & R = \set{ ret(m,d,k) : m \in \<Methods>, d \in \<Vals>, k \in \<Ops> }  
\end{align*}
of \emph{call actions} and \emph{return actions}; each call action $inv(m,d,k)$
combines a method $m \in \<Methods>$ and value $d \in \<Vals>$ with an
\emph{operation identifier} $k \in \<Ops>$. Operation identifiers are used to
pair call and return actions. We denote the operation identifier of a
call/return action $a$ by $\<op>(a)$. Call and return actions $c \in C$ and $r
\in R$ are \emph{matching}, written $c \match r$, when $\<op>(c) = \<op>(r)$. 
We may omit the second field from a call/return action $a$ for methods that have no inputs \textcolor{red}{(e.g., the pop method of a stack)}or return values \textcolor{red}{(e.g., the push method of a stack)} 
(e.g., the pop method of a stack).
A word $\tau \in @S^*$ over alphabet $@S$, such that $(C \u R) \subseteq @S$, is
\emph{well formed} when:
\begin{itemize}

  \item Each return is preceded by a matching call: \\
  $\tau_j \in R$ implies $\tau_i \match \tau_j$ for some $i < j$.

  \item Each operation identifier is used in at most one call/return: \\
  $\<op>(\tau_i) = \<op>(\tau_j)$ and $i < j$ implies $\tau_i \match \tau_j$.

\end{itemize}
We say that the well-formed word $\tau \in @S^*$ is \emph{sequential} when
\begin{itemize}

  \item Operations do not overlap: \\
  $\tau_i, \tau_k \in C$ and $i < k$ implies $\tau_i \match \tau_j$ for some $i < j < k$.

\end{itemize}
Well-formed words represent traces of a library. We assume every set of well-formed
words is closed under isomorphic renaming of operation identifiers. For
notational convenience, we take $\<Ops>=\<Nats>$ for the rest of the paper.
When the value of a certain field in a call/return action is not important we use 
the placeholder $\_$, e.g., $inv(m,\_,k)$ instead of $inv(m,d,k)$ when the input  
$d$ can take any value.

An operation $k$ is called \emph{completed} in a well-formed trace $\tau$ when
$ret(m,d,k)$ occurs in $\tau$, for some $m$ and $d$. Otherwise, it is called \emph{pending}.
%An operation $o$ of an execution $e$ is \emph{completed}
%when both call and return actions $m(u)_o$ and $\<ret>(v)_o$ of $o$ occur in
%$e$, and is otherwise \emph{pending}.

%\begin{example}
%  \label{ex:executions}
%
%  TODO
%
%  The well-formed words
%  \scriptsize
%  \begin{align*}
%     \<push>(0)_1\ \<pop>_2\ \<pop>_3\ \<ret>_1\ \<ret>(0)_3\ \<ret>(0)_2
%    \text{\normalsize, and } 
%    \<push>(0)_1\ \<pop>_2\ \<pop>_3\ \<ret>_1\ \<ret>(0)_2
%  \end{align*}
%  \normalsize
%  represent executions in which one call to the $\<push>(0)$ method overlaps
%  with two calls to $\<pop>$. In the first execution both calls to $\<pop>$
%  have matching return actions $\<ret>(0)$, i.e., the operations $2$ and $3$ are completed,
%  while operation $3$ is pending in the second, it has no matching return.
%
%\end{example}

Libraries dictate the execution of methods between their call and return
points. Accordingly, a library cannot prevent a method from being called,
though it can decide not to return. Furthermore, any library action performed
in the interval between call and return points can also be performed should the
call have been made earlier, and/or the return made later. 
A library thus allows any sequence of
invocations to its methods made by \emph{some} program.

\begin{definition}\label{def:libraries}
A \emph{library} $L$ is an LTS over alphabet $\Sigma$ such that $C \u R\subseteq \Sigma$
and each trace $\tau \in Tr(L)$ is well formed, and
  \begin{itemize}

    \item Call actions $c \in C$ cannot be disabled: \\
    $\tau \cdot \tau' \in Tr(L)$ implies $\tau \cdot c \cdot \tau' \in Tr(L)$
    if $\tau \cdot c \cdot \tau'$ is well formed.
  
    \item Call actions $c \in C$ cannot disable other actions: \\
    $\tau \cdot a \cdot c \cdot \tau' \in Tr(L)$ implies $\tau \cdot c \cdot a \cdot \tau' \in Tr(L)$.
  
    \item Return actions $r \in R$ cannot enable other actions: \\
    $\tau \cdot r \cdot a \cdot \tau' \in Tr(L)$ implies $\tau \cdot a \cdot r \cdot \tau' \in Tr(L)$.
  
  \end{itemize}

\end{definition}

The projection of a library trace over $C\cup R$ is called a \emph{history}. The set of histories of a library $L$ is denoted by $H(L)$.

Note that even a library that implements \emph{atomic methods}, e.g.,~by
guarding method bodies with a global-lock acquisition, admits executions in
which method calls and returns overlap. 
%A library which accesses the client's
%thread identifiers can be modeled by taking thread identifiers as method
%parameters.

\textcolor{red}{For the below paragraph, I cannot see the equivalence  of informal explanation and formal definition of weakening. I think the formal one should be if a ret comes before a call in $h_1'$ then this order is preserved in $h_2$. But the definition says iff. Ignore this if I am wrong.}
Since libraries only dictate methodsâ€™ executions between their respective calls and returns, for any history they admit, they must also 
admit histories with weaker inter-operation ordering, in which calls may happen earlier, and/or returns later. This weakening relation
between histories can be formalized as follows: a history $h_1$ is \emph{weaker} than a history $h_2$, written $h_1 \sqsubseteq h_2$, 
if{f} there exists a well-formed history $h_1'$
obtained from $h_1$ by appending return actions, and deleting call actions,
such that:
\begin{quote}

  $h_2$ is a permutation of $h_1'$ that preserves the order between
  return and call actions, i.e.,~a given return action occurs before a given
  call action in $h_1'$ if{f} the same holds in $h_2$.

\end{quote}

$\overline{H}$ denotes the closure $\set{h: \exists h' \in H.\ h \sqsubseteq h'}$ of a 
history set $H$ under weakening.
A direct consequence of Definition~\ref{def:libraries} is that $H(L)=\overline{H(L)}$ for
every library $L$. A \emph{kernel} of L is any set $H$ such that $\overline{H} = L$ \textcolor{red}{(I think the correct expression is $\overline{H} = H(L)$ which makes the example set $H$ and the operator $H$  that extracts history from a library confusing with each other)}.
A library $L$ is called atomic if it has a sequential kernel. 
Atomic libraries are often considered as specifications for concurrent objects. 
In practice, libraries can be made atomic by guarding their methods bodies with global lock acquisitions.


%\begin{example}
%  \label{ex:libraries}
%
%  TODO (replace executions with histories)
%
%  Any library which admits the execution
%  \scriptsize
%  \begin{align*}
%    \<push>(0)_1\ \<ret>_1\ \<pop>_2\ \<ret>(0)_2
%  \end{align*}
%  \normalsize
%  with sequential calls to $\<push>$ and $\<pop>$ must also admit
%  \scriptsize
%  \begin{align*}
%    \<push>(0)_1\ \<pop>_2\ \<ret>_1\ \<ret>(0)_2
%    \text{ \normalsize and }
%    \<push>(0)_1\ \<pop>_2\ \<pop>_3\ \<ret>_1\ \<ret>(0)_2
%    \text{\normalsize,}
%  \end{align*}
%  \normalsize
%  among others, yet need not admit an execution
%  \scriptsize
%  \begin{align*}
%    \<push>(0)_1\ \<pop>_2\ \<pop>_3\ \<ret>_1\ \<ret>(0)_3\ \<ret>(0)_2
%  \end{align*}
%  \normalsize
%  with two completed $\<pop>$ operations returning $0$.
%  
%\end{example}




%Systems we consider are labeled transition systems (LTS):
%\begin{dfn}
%An LTS is defined over four-tuples $A=(Q,\Sigma, q_0, \delta)$ where $Q$ is the set of states, $\Sigma$ is the set of transition labels, $q_0 \in Q$ is the initial state and $\delta \subseteq Q \times \Sigma \times Q$ is the transition relation.
%\end{dfn}
%Executions generated by this system are alternating sequence of states and transition labels $\rho = s_0, e_0, s_1,... s_k, e_k,...$ where each $s_i \in Q$, each $e_i \in \Sigma$, $s_0 = q_0$ and each $(s_i, e_i s_{i+1}) \in \delta$. The projection of the sequence $\rho$ over the set $\Pi$ is denoted by $\rho | \Pi$, and it is the maximum subsequence of $\rho$ consisting of elements of $\Pi$. Traces of the LTS are obtained from executions by projecting them over $\Sigma$. For the rest of the paper and in all of the proofs, we consider only finite executions (denoted as $E(A)$) and/or traces (denoted as $Tr(A)$ of the LTSs in focus.

%Libraries are LTSs that provide methods. Let $\mathcal{M}$ be the set of method names and $\mathcal{D}$ be the domain of values as input/output parameters for the methods. Then, this library contains transition labels of the form $inv(m,d,i)$ representing the invocation of method $m \in \mathcal{M}$ with input value $d \in \mathcal{D}$. The third field is the operation identifier for differentiating the different calls of the same method from the set $\mathcal{O}$. For simplicity, we take $\mathcal{O} = \mathbb{N}$ for the rest of the paper. We also assume that methods could have at most one input parameter. If they do not have any input arguments (like pop method of a stack), we can omit the second field from the action. They also provide actions of the form $ret(m,d,i)$ representing the return of method $m \in M$ with value $d \in D$ which has been invoked previously with action $inv(m,d',i)$. Again, we assume that the methods can return at most one parameter and we may omit the second field from the action if they have none (like enqueue method of a queue). Before starting to reason about any set of libraries, we first fix the sets $\mathcal{M}$ and $\mathcal{D}$ and libraries in our focus agree on this sets. For any transition label $e = inv(m,d,i)$ or $e=ret(m,d,i)$, we have the function $oid(e) = i$.
%
%Since libraries are LTSs, they produce traces. A trace $e = e_1, e_2, ..., e_n$ of library $L$ is \emph{well-formed} iff (i) every return matches an earlier invocation: $e_j = ret(m,d,k)$ implies that there exists $i<j$ such that $e_i = inv(m,d',k)$ and (ii) every operation identifier is used at most one invocation/return pair: $oid(e_i) = oid(e_j) = k$ and $i<j$ implies $e_i = inv(m,d,k)$ and $e_j = ret(m,d',k)$. From now on, we assume that libraries produce well-formed traces. Let $f: \mathbb{N} \rightarrow \mathbb(N)$ be a bijection. Then, traces $e$ and $e'$ are equivalent if $e'$ is obtained from $e$ by replacing every action $inv(m,d,k)$ with $inv(m,d,f(k))$ and every action $ret(m,d,k)$ with $ret(m,d,f(k))$. 

\subsection{Refinement and Linearizability}

\textcolor{red}{A general organizational idea for  this subsection: Linearizability is defined in terms of weakening in which observational actions are just call and return events. Then, we put forward the idea of enriching $\Gamma$ by adding new actions. In the current organization, linearizability is defined after refinement before which this $\Gamma$ extension argument is explained. Hence, people may confuse that notion of linearizability is based on $\Gamma$ set we picked. I propose to first introduce linearizability. Then explain refinement and give Theorem 1.}
Conformance of a library $L_1$ to a specification given as an ``abstract'' library $L_2$ 
is formally captured by \emph{(observational) refinement}. Informally, given two libraries
$L_1$ and $L_2$ implementing the methods of some concurrent object, we
say $L_1$ refines $L_2$ if{f} every computation of every program
using $L_1$ would also be possible were $L_2$ used instead. As shown in~\citet{journals/tcs/FilipovicORY10,DBLP:conf/popl/BouajjaniEEH15},
refinement is equivalent to the \emph{linearizability} criterion~\cite{journals/toplas/HerlihyW90} when $L_2$ is an atomic library. 
Refinement can be proved using \emph{forward/backward simulation relations} which roughly, guarantee that steps
in the concrete library correspond to (sequences of) steps in the abstract library.

\begin{dfn}
\textcolor{red}{We assign same alphabet to both libraries in the definition but we say libraries can be defined over distinct alphabets as long as they share $\Gamma$ which is the case in our week machine. Why don't we define refinement like that at the first place?}
Let $L_1$ and $L_2$ be two libraries over a common alphabet $\Sigma$, and $\Gamma\subseteq \Sigma$ a set of actions such that $(C\cup R)\subseteq \Gamma$~\footnote{The two libraries could be defined over different alphabets as long as they share $\Gamma$.}. 
%agreeing on $\mathcal{M}$ and $\mathcal{D}$ sets. We define the set $A\Sigma = \{inv(m,d,i)| m \in \mathcal{M} \wedge d \in \mathcal{D} \wedge i \in \mathbb{N}\} \cup \{ret(m,d,i)| m \in \mathcal{M}\wedge d \in \mathcal{D} \wedge i \in \mathbb{N}\}$ as abstract transition labels. Note that $A\Sigma \subseteq \Sigma_{L_1}$ and $A\Sigma \subseteq \Sigma_{L_2}$. 
The library $L_1$ \emph{$\Gamma$-refines} $L_2$ if{f} $Tr(L_1) | \Gamma \subseteq Tr(L_2) | \Gamma$.
%We say that $L_1$ \emph{refines} $L_2$ when $H(L_1) \subseteq H(L_2)$.
%for every trace $e \in Tr(L_1)$, there exists a trace $e' \in Tr(L_2)$ such that $e|A\Sigma$ is equivalent to $e'|A\Sigma$.
\end{dfn}
The actions in $\Gamma$ are called \emph{observable actions}. Usually, $\Gamma$ consists only of call and return actions \textcolor{red}{(For this case we say just refinement instead of $\Gamma-refinement$. We need to add this sentence since we say just refinement in Theorem 1.)}. As we show in the next sections, increasing the set of observable actions is useful in simplifying proofs of refinement.
%Linearizability is also a relation between two libraries and it is stricter than refinement. It requires $e'$ in Definition 2 to be a sequential one. A trace $e$ is sequential iff following two conditions hold for its projection to abstract transition labels $e|A\Sigma = e_1, ...e_n$: $(i)$ $e_1 = inv(m,d,k)$ for some $m \in \mathcal{M}, d \in \mathcal{D} and k \in \mathbb{N}$ and $(ii)$ for all $i \in [1,n)$, either $e_i = inv(m,d,k)$ and $e_{i+1} = ret(m,d',k)$ or $e_i = ret(m,d,k)$ and $e_{i+1} = inv(m',d',k')$ for some $m,m' \in \mathcal{M}$, $d,d' \in \mathcal{D}$ and $k,k' \in \mathbb{N}$.

Linearizability~\cite{journals/toplas/HerlihyW90} requires that 
the operations of a concurrent library seem to take effect instantaneously at some point in time just like atomic
implementations even if they use fine-grained concurrency and they overlap in time. The point in time
where an operation is conceptually effectuated is called a \emph{linearization point}. There are two ways of
defining linearizability, using the weakening order $\sqsubseteq$ between histories or using linearization points.

%For some libraries,
%the linearization points of (some of) the operations are fixed to particular implementation actions and they
%can be exposed 

A history $h_1$ is \emph{linearizable} w.r.t.~a library $L_2$ if{f} there exists a sequential history
$h_2 \in H(L_2)$, with only
completed operations, such that $h_1 \sqsubseteq h_2$. A library $L_1$
is \emph{linearizable} w.r.t. $L_2$, written $L_1 \sqsubseteq L_2$, if{f}
each history $h_1 \in H(L_1)$ is linearizable w.r.t. $L_2$.

\textcolor{red}{An organizational concern: Do we really need the second definition of linearizability? I think our aim here is to introduce both refinement and linearizability and relate them via Thm 1. I cannot see any contribution of this part until Thm 1. You may ignore this message if I am missing something important about the second definition.}
The weakening order w.r.t. sequential histories can be also defined  in terms of ~\emph{linearization points}. 
%A linearization point 
%corresponds to a transition in that
%execution that occurs between the call and the return action of the operation.
A \emph{linearization point annotation} (LP-annotation for short) of a history $h$ is a sequence $\hat{h}$ obtained from $h$ by inserting actions $lin(m,d,k)$ with $m\in\<Methods>$, $d\in\<Vals>$ and $k\in \<Ops>$ such that:
\begin{itemize}
	\item every linearization point corresponds to an operation that has been called, i.e., TODO
	\item every linearization point occurs between the call and the return of the corresponding operation, i.e., TODO
	\item the return value of an operation is fixed by the linearization point, i.e., TODO
\end{itemize}
An LP-annotation is called \emph{complete} when every completed operation has a linearization point, i.e., TODO.
An operation $k$ is called \emph{effectuated} in a complete LP-annotation $\hat{h}$ when  $\hat{h}$ contains $lin(\_,\_,k)$. 

For a history $h_1$ and a sequential history $h_2$, $h_1 \sqsubseteq h_2$ if{f} there exists a complete LP-annotation $\hat{h_1}$ such that  
$h_2$ is a permutation of the history $h_1'$ obtained from $h_1$ by preserving only call/return actions of effectuated operations that preserves the linearization point order, i.e.,~a given return action $ret(\_,\_,k)$ occurs before a given
  call action $call(\_,\_,k')$ in $h_2$ if{f} $lin(\_,\_,k)$ occurs before $lin(\_,\_,k')$ in $\hat{h_1}$.


\begin{theorem}[\cite{journals/tcs/FilipovicORY10,DBLP:conf/popl/BouajjaniEEH15}]
  $L_1 \sqsubseteq L_2$ if{f} $L_1$ refines $L_2$,
  if $L_2$ is atomic.

\end{theorem}

We define a notion of \emph{forward} simulation whose existence implies refinement, and it is equivalent to refinement when the right-hand side library $L_2$ is deterministic \textcolor{red}{(do we need to define deterministic?)}. A dual notion of \emph{backward} simulation is defined in Appendix~\ref{app:backSim}. The existence of backward simulations is equivalent to refinement for arbitrary libraries.
%We define a notion of forward simulation that is a sound approximation of refinement and a notion of backward simulation that precisely characterizes refinement. 
For a relation $R\subseteq A\times B$, $R[X]$ denotes the set of elements of $B$ related to elements of $X$ by $R$, i.e., $R[X]=\set{y:\exists x\in X.\ R(x,y)}$.

%We can extend the relations between libraries by introducing simulation relations. We will later show that simulation relations imply refinement. 

\begin{dfn}
Let $L_1=(Q_1,\Sigma, q_0^1, \delta_1)$ and $L_2=(Q_2,\Sigma, q_0^2, \delta_2)$ be two libraries over a common alphabet $\Sigma$, and $\Gamma\subseteq \Sigma$ a set of actions such that $(C\cup R)\subseteq \Gamma$. A relation $\mathit{fs} \subseteq Q_{1} \times Q_{2}$ is called a \emph{$\Gamma$-forward simulation} from $L_1$ to $L_2$ iff the following holds:
\begin{itemize}
\item[(i)] $\mathit{fs}[s_0^1] = \{s_0^2 \}$ \textcolor{red}{Either we need to change $s_0^1$ to $q_0^1$ here or vice versa in the first line of the definition.}
\item[(ii-a)] If $(s,c,s') \in \delta_1$, for some $c\in C$, and $u \in \mathit{fs}[s]$, then there exists $u' \in \mathit{fs}[s']$ such that $u \xrightarrow{@s} u'$, $@s_0=c$, and $@s_i\in \Sigma\setminus(C\cup R)$ \textcolor{red}{($@s_i\in \Sigma\setminus \Gamma$)}, for each $0<i<|@s|$.
%$@s = a_1, a_2, ..., a_n$ such that $a_1 = inv(m,d,k)$ and for all $i \in [2,n]$, $a_i \in \Sigma_{L_2} \backslash A\Sigma $. The expression $u \xrightarrow{a} u'$ means that there exists a sequence of states $u_1, u_2,...,u_{n+1}$ such that $u_1 = u$, $u_{n+1} = u'$ and for all $i \in [1,n]$, $(u_i, a_i, u_{i+1}) \in \delta_{L_2}$.
\item[(ii-b)] If $(s,r,s') \in \delta_{1}$, for some $r\in R$, and $u \in \mathit{fs}[s]$, then there exists $u' \in \mathit{fs}[s']$ such that $u \xrightarrow{@s} u'$, $@s_{|@s| -1}=r$, and $@s_i\in \Sigma\setminus(C\cup R)$  \textcolor{red}{($@s_i\in \Sigma\setminus \Gamma$)}, for each $0\leq i<|@s| -1$.
% where $a = a_1, a_2, ..., a_n$ such that $a_n = ret(m,d,k)$ and for all $i \in [1,n-1]$, $a_i \in \Sigma_{L_2} \backslash A\Sigma $. 
\item[(ii-c)] If $(s, \gamma , s') \in \delta_1$, for some $\gamma\in \Gamma\setminus (C\cup R)$, and $u \in fs[s]$, then there exists $u' \in fs[s']$ such that $u\xrightarrow{\gamma} u'  \in \delta_2$. \textcolor{red}{$(u,\gamma, u') \in \delta_2$ instead of $u\xrightarrow{\gamma} u'  \in \delta_2$?)}
\item[(ii-d)] If $(s,e,s') \in \delta_1$, for some $e \in \Sigma\setminus \Gamma$ and $u \in \mathit{fs}[s]$, then there exists $u' \in \mathit{fs}[s']$ such that $u \xrightarrow{\sigma} u'$ and $@s_i\in \Sigma\setminus(C\cup R)$  \textcolor{red}{($@s_i\in \Sigma\setminus \Gamma$)}, for each $0\leq i<|@s|$.  \textcolor{red}{(All of the above changes also apply to the backward simulation definition in appendix.)}
%where $a = a_1, a_2, ..., a_n$ such that for all $i \in [1,n]$, $a_i \in \Sigma_{L_2} \backslash A\Sigma $. Moreover, $a$ could be the empty sequence.
\end{itemize}
\end{dfn}
%If $\mathit{fs}[s]$ is a unique state for all $s \in Q_1$ then $\mathit{fs}$ is called a refinement mapping/function. 
A $\Gamma$-forward simulation establishes that $L_2$ can mimic every step of $L_1$ using a (possibly empty) sequence of steps. In order to imply $\Gamma$-refinement, steps of $L_1$ labeled by observable actions are treated in a particular way: a step of $L_1$ labeled by a call, resp., return, action is simulated by a sequence of steps of $L_2$ that start, resp., end, with the same action, and a step of $L_1$ labeled by another observable action should be matched by a step of $L_2$ labeled by the same action. The rest of the transitions in $L_1$ must be simulated by a possibly empty sequence of transitions of $L_2$ (with arbitrary labels).

Simulation relations are used to prove refinement among libraries. The following lemma shows their soundness and their completeness (when $L_2$ is deterministic).
\begin{lem}
Let $L_1$ and $L_2$ be two libraries over a common alphabet $\Sigma$, and $\Gamma\subseteq \Sigma$ a set of actions such that $(C\cup R)\subseteq \Gamma$. If there exists a $\Gamma$-forward simulation from $L_1$ to $L_2$, then $L_1$ $\Gamma$-refines $L_2$. Moreover, if $L_2$ is deterministic and $L_1$ $\Gamma$-refines $L_2$, then there exists a $\Gamma$-forward simulation from $L_1$ to $L_2$.
\end{lem}
\begin{proof}
Looks trivial and follows Lynch paper. Can be completed later.
\end{proof}



