%!TEX root = draft.tex
\section{Introduction}

Efficient concurrent implementations of atomic collections including stacks and queues are vital to modern computer systems. Programming them is however error prone. To minimize synchronization overhead between concurrent method invocations, implementors avoid blocking operations like lock acquisition, allowing methods to execute concurrently. However, concurrency risks unintended inter-operation interference, and risks conformance to atomic reference implementations. Conformance is formally captured by \emph{observational refinement}, which assures that all behaviors of programs
using these efficient implementations would also be possible were the atomic reference implementations used instead.

Observational refinement can be formalized as a trace inclusion problem, and the latter can itself be reduced to an assertion (invariant) checking problem, but this requires in general the consideration of additional history and prophecy variables. Alternatively, verifying observational refinement requires in general establishing both a forward simulation {\em and} a backward simulation. While simulations are natural concepts, reasoning about backward simulations, corresponding to the use of prophecy variables, is however less intuitive, and from the practical point of view, backward reasoning is in general hard and complex for programs manipulating data structures. Therefore, a crucial issue is to understand the limits of forward reasoning in establishing observational refinement. More precisely, we consider that an important question is to determine for which concurrent abstract data structures, and for which types of their implementation, is it possible to carry out an observational refinement proof using only forward reasoning.

In order to get rid of backward simulations (and equivalently of prophecy variables), it is necessary to have reference implementations of the considered abstract data structures that are {\em deterministic}. Interestingly, determinism allows also to simplify the forward simulation checking problem. Indeed, in this case, this problem can be reduced to an invariant checking problem. Basically, the simulation relation can be seen as an invariant of the system composed by the two compared programs. Therefore, existing methods and tools for invariant checking can be leveraged in the context of proving observational refinement. 

But, in order to determine precisely what is meant by determinism, an important point is to fix the alphabet of observable events along computations. 
Typically, to reason about observational refinement between two library implementations, the only observable events are the calls and returns corresponding to the method invocations along computations. This means that only the external interface of the library is considered to compare behaviors, and nothing else from the implementations is exposed. Unfortunately, it can be shown that in this case, it is impossible to have deterministic atomic reference implementations for common data structures such as stacks and queues (see, e.g., \cite{DBLP:conf/cav/SchellhornWD12}). Then, an important question is what is the necessary amount of information that should be exposed by the implementations to overcome this problem ?

One approach addressing this question is based on the notion of linearizability \cite{journals/toplas/HerlihyW90} and its correspondence with observational refinement (w.r.t. atomic reference implementations) \cite{journals/tcs/FilipovicORY10,DBLP:conf/popl/BouajjaniEEH15}. Linearizability of a computation (of some concurrent implementation) means that each of the method invocations can be seen as happening at some point, called {\em linearization point}, occurring somewhere between the call and return events of that invocation, such that the obtained sequence of linearization points along the computation defines a sequence of operations that is possible in the atomic reference implementation. Proving the existence of such sequences of linearization points, for all the computations of a concurrent library, is a complex problem \cite{journals/iandc/AlurMP00,conf/esop/BouajjaniEEH13,DBLP:conf/netys/Hamza15}. 
%
However, proving linearizability becomes less complex when linearization points are fixed for each method, i.e., associated (once and for all) with the execution of a designated statement in its source code \cite{conf/esop/BouajjaniEEH13}. In this case, we can consider that libraries expose not only the call and returns events, but also events signaling linearization points. By extending this way the alphabet of observable events, it becomes straightforward to define {\em deterministic} atomic reference implementations. Therefore, proving linearizability can be carried out as an invariant checking problem when linearization pointst are fixed, e.g.,~\cite{conf/ppopp/VafeiadisHHS06,conf/cav/AmitRRSY07,conf/vmcai/Vafeiadis09,conf/tacas/AbdullaHHJR13}.
%
While this approach can be useful in some cases, it is unfortunately not applicable to many efficient implementations such as the LCRQ queue~\cite{DBLP:conf/ppopp/MorrisonA13} (based on the principle of the Herlihy\&Wing queue \cite{journals/toplas/HerlihyW90}), and the Time-Stamped Stack \cite{DBLP:conf/popl/DoddsHK15}. The proofs of linearizability of these implementations are highly nontrivial, very involved, and hard to read, understand and automatize. Therefore, the crucial question we address is what is precisely the kind of information that is necessary to expose in order to obtain deterministic atomic reference implementations for such data structures, allowing to derive simple and natural linearizability proofs for such complex implementations, which can be carried out as systematic invariant checking proofs that are amenable to automation?

We observe that the main difficulty in reasoning about these implementations is that, linearization points of enqueue/push operations occurring along some given computation, depend in general on the linearization points of dequeue/pop operations that are occurring later in that computation, at arbitrary far positions. Therefore, since linearization points for enqueue/push operations cannot be determined in advance, the information that could be fixed and exposed can concern only the dequeue/pop operations. 

One first idea is to consider that linearization points are fixed for dequeue/pop methods and only for these methods. We show that under the assumption that implementations expose linearizations points for these methods, it is possible to define deterministic atomic reference implementations for both queues and stacks. We show that this is indeed useful by providing a simple proof of the Herlihy\&Wing queue (based on establishing a forward simulation) that can be carried out as an invariant checking proof.

However, in the case of the Time-Stamped Stack, fixing linearization points of pop operations is actually too restrictive. Nevertheless, we show that our approach can be generalized to handle this case. The key idea is to reason about what we call {\em commit points}, and  that correspond roughly speaking to the last point a method accesses to the shared data structure during its execution. We prove that by exposing commit points (instead of linearization points) for pop methods, we can still provide deterministic reference implementations. We show that using this approach leads to a quite simple proof of the Time-Stamped Stack.


%Efficient implementations of concurrent objects such as semaphores, locks, and atomic collections including stacks and queues are vital to modern computer systems. Programming them is however error prone. To minimize synchronization overhead between concurrent object-method invocations, implementors avoid blocking operations like lock acquisition, allowing methods to execute concurrently. However, concurrency risks unintended inter-operation interference, and risks conformance to atomic reference implementations. Conformance is formally captured by \emph{observational refinement}, which assures that all behaviors of programs
%using these efficient implementations would also be possible were the atomic
%reference implementations used instead.
%An equivalent property is \emph{linearizability}~\cite{journals/toplas/HerlihyW90} which requires that each concurrent execution
%has a linearization which is a valid sequential execution according to a
%specification, given by an abstract data type or reference implementation.
%
%Existing proof methods for refinement/linearizability combine reductions to assertion checking with compositional reasoning techniques for proving the assertions.
%
%The reductions to assertion checking are based on simulation relations: the assertions describe a simulation relation to standard atomic reference implementations
%
%No surprise, simulations are the standard approach for proving refinement
%
%This works smoothly for particular classes of implementations, e.g., with fixed linearization points. The explanation is that in this case, forward simulations are enough and the reference implementation is deterministic when the linearization points are observable
%
%Why they are enough ? Forward simulations are not complete for proving refinement: the reference implementation is not deterministic when projected over call and returns. 
%
%However, in this case, the set of observable actions includes the linearization points. And the reference implementations becomes deterministic for this larger set of observable actions.
%
%Determinism also simplifies the assertions
%
%When linearization points are not observable, reference implementations are not deterministic and one may need backward simulations. There is a paper arguing for this fact ~\cite{DBLP:conf/cav/SchellhornWD12}.
%
%However, using backward simulations is hard, they require prophecy variables. They are not good for automation.
%
%Question: We want to avoid backward simulations, so what can we do about implementations without fixed linearization points, e.g, Herlihy\&Wing, Time-Stamped Stack ? Can they be proved using forward simulations ?
%
%We answer positively for queues and stacks. The idea is to define new abstract implementations over a set of observable actions bigger than the set of call/returns, but smaller than all linearization points.
%
%Queues: only dequeues have fixed linearization points.
%
%Stacks: pops have fixed commit points
%
%\newpage%~\newpage
